{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Implementation\n",
    "### Mandarin Word Segmentation Using BaumWelch HMM\n",
    "For my semisupervised I attempted using the Baum Welch algorithm for tuning probabilities, using 1% of the provided training data (supervised portion) as initialization. I then ran the generated probabilities through the Viterbi algorithm to generate predicted sequences.\n",
    "Unfortunately my implmentation performs extremely poorly. I was barely able to get over 50%, which is significantly worse than blindly guessing '1' every character (65% of the training data had the '1' tag). Understanding and implementing BaumWelch proved extremely difficult, but I think the failure to reach proper probabilities was due to precision flaws. When testing my code using the data from the spreadsheet, my results matched up for about 6-8 rows but then began to diverge more and more. I'm pretty sure this indicates differences in rounding/precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import log\n",
    "import numpy as np\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment variables. **Set `train_file` and `test_file` to the relative filepaths of the data.** If `test_file` is an empty string no test data will be used.\n",
    "I set the validation split to be 99% here so I'm only using 1% of the training labels, per the challenge requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file: str = 'data/train.tsv'\n",
    "test_file: str = 'data/test.tsv'\n",
    "val_split: float = 0.99\n",
    "\n",
    "states: dict = {\n",
    "    '0': 0,\n",
    "    '1': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file: str) -> list:\n",
    "    print(\"Loading data from file {}...\".format(file))\n",
    "    file = open(file, 'r')\n",
    "    data = []\n",
    "    for line in file:\n",
    "        pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        data.append(pieces)\n",
    "    print(\"Loaded {} sentences\".format(len(data)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file data/train.tsv...\n",
      "Loaded 8368167 sentences\n"
     ]
    }
   ],
   "source": [
    "train_data: list = load_data(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file data/test.tsv...\n",
      "Loaded 197696 sentences\n",
      "Splitting data...\n",
      "8284486  validation characters\n",
      "83681  training characters\n"
     ]
    }
   ],
   "source": [
    "if len(test_file) > 0:\n",
    "    test_data: list = load_data(test_file)\n",
    "print(\"Splitting data...\")\n",
    "num_train_samples: int = int(len(train_data)*(1-val_split))\n",
    "val_data: list = train_data[num_train_samples:]\n",
    "print(len(val_data), \" validation characters\")\n",
    "train_data: list = train_data[:num_train_samples]\n",
    "print(len(train_data), \" training characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æ™‚', '0']\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions taken from my Celtic Mutations code. They'll be used to compute the initialization probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities_from_counts(counts_dict: dict) -> dict:\n",
    "    counts_sum: int = sum(counts_dict.values())\n",
    "    probabilities_dict: dict = {}\n",
    "    for count_id in counts_dict:\n",
    "        count = counts_dict[count_id]\n",
    "        probabilities_dict[count_id] = count / counts_sum\n",
    "    assert round(sum(probabilities_dict.values()), 2) == 1.0, \"All probabilities should sum to 1 but got {}\".format(round(sum(probabilities_dict.values()), 2))\n",
    "    return probabilities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_with_max_val(d: dict) -> str:\n",
    "    \"\"\"https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\"\"\"\n",
    "    v = list(d.values())\n",
    "    k = list(d.keys())\n",
    "    return k[v.index(max(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions were adapted from my Celtic Mutations HMM to generate the initialization probabilities based on the first 1% of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_state_probabilities(data: list) -> dict:\n",
    "    initial_state_counts: dict = states.copy()\n",
    "    # equal probability of starting\n",
    "    for state in initial_state_counts:\n",
    "        initial_state_counts[state] += 1\n",
    "    initial_state_probabilities: dict = compute_probabilities_from_counts(initial_state_counts)\n",
    "    return initial_state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transition_state_probabilities(data: list) -> dict:\n",
    "    # create a dictionary with two levels, the first being the previous state and the second being the current state\n",
    "    transition_state_counts: dict = {state: states.copy() for state in states}\n",
    "    # since we enumerate over a list that excludes the first item, the enumeration index is one behind\n",
    "    for prev_idx, word in enumerate(data[1:]):\n",
    "        prev_state: str = data[prev_idx][1]\n",
    "        current_state: str = word[1]\n",
    "        if prev_state in transition_state_counts and current_state in transition_state_counts[prev_state]:\n",
    "            transition_state_counts[prev_state][current_state] += 1\n",
    "    # setting STOP count to 1 for all states to avoid zeros\n",
    "    for state in transition_state_counts:\n",
    "        transition_state_counts[state]['STOP'] = 1\n",
    "    transition_state_probabilities: dict = {state: {} for state in states}\n",
    "    for prev_state in transition_state_counts:\n",
    "        transition_state_probabilities[prev_state] = compute_probabilities_from_counts(transition_state_counts[prev_state])\n",
    "    return transition_state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emission_probabilities(data: list, all_observations: list) -> dict:\n",
    "    vocab = {obs: 1 for obs in set(all_observations)}\n",
    "    emission_counts_by_state: dict = {state: vocab for state in states}\n",
    "    for word_state_pair in data:\n",
    "        word, state = word_state_pair\n",
    "        if state in emission_counts_by_state:\n",
    "            # initialize word in state dict if the first occurrence of word X in state Y\n",
    "            if word not in emission_counts_by_state[state]:\n",
    "                emission_counts_by_state[state][word] = 0\n",
    "            emission_counts_by_state[state][word] += 1\n",
    "    emission_probabilities_by_state: dict = {state: {} for state in states}\n",
    "    for state in emission_counts_by_state:\n",
    "        emission_probabilities_by_state[state] = compute_probabilities_from_counts(emission_counts_by_state[state])\n",
    "    return emission_probabilities_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data: list, vocab: list) -> tuple:\n",
    "        print(\"Fitting model to provided dataset...\")\n",
    "        initial_state_probabilities = generate_initial_state_probabilities(data)\n",
    "        transition_probabilities = generate_transition_state_probabilities(data)\n",
    "        emission_probabilities = generate_emission_probabilities(data, vocab)\n",
    "        print(\"Model ready.\")\n",
    "        return initial_state_probabilities, transition_probabilities, emission_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I divide the validationb data between labels and characters, and fit the initial probabilities to the first 1% of training data.\n",
    "I pass the validation samples into the fit function for the sake of creating a dictionary of observations for emissions probabilities, but **the `val_sequence` variable does not include the labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model to provided dataset...\n",
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "val_sequence = [pair[0] for pair in val_data]\n",
    "val_labels = [pair[1] for pair in val_data]\n",
    "initial, transition, emission  = fit(train_data, val_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are each based on a section of the [Eisner HMM spreadsheet](https://docs.google.com/spreadsheets/d/1E4CKgcP9KmNsN6d-DWEYMuKBh-PFyXeswu48Axg6IQQ/edit#gid=1059181785). This is where I had the precision issues that prevented my implementation from reaching expected performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_prob(observations: list) -> dict:\n",
    "    forward_probabilities: dict = {}\n",
    "    for idx, observation in enumerate(observations):\n",
    "        for state in initial:\n",
    "            if idx == 0:\n",
    "                probability = initial[state]*emission[state][observation] if observation in emission[state] else 0\n",
    "                forward_probabilities[state] = torch.DoubleTensor([probability])\n",
    "            else:\n",
    "                probability = 0\n",
    "                for prev_state in transition:\n",
    "                    probability += forward_probabilities[prev_state][idx-1]*transition[prev_state][state]\n",
    "                probability *= emission[state][observation]\n",
    "                forward_probabilities[state] = torch.cat((forward_probabilities[state], torch.DoubleTensor([probability])))\n",
    "    return forward_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backward_prob(observations: list) -> dict:\n",
    "    backward_probabilities: dict = {}\n",
    "    for i in range(len(observations)):\n",
    "        idx = len(observations)-i-1\n",
    "        for state in initial:\n",
    "            if idx == len(observations)-1:\n",
    "                probability = transition[state]['STOP']\n",
    "                backward_probabilities[state] = torch.DoubleTensor([probability])\n",
    "            else:\n",
    "                probability = 0\n",
    "                for next_state in transition:\n",
    "                    probability += backward_probabilities[next_state][0]*transition[state][next_state]*emission[next_state][observations[idx+1]]\n",
    "                backward_probabilities[state] = torch.cat((torch.DoubleTensor([probability]), backward_probabilities[state]))\n",
    "    return backward_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_total_prob(forward_prob: dict, backward_prob: dict) -> dict:\n",
    "    state_total_prob: dict = {}\n",
    "    for state in forward_prob:\n",
    "        state_total_prob[state] = forward_prob[state] * backward_prob[state]\n",
    "    return state_total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_prob(state_total_prob: dict, observations: list) -> torch.DoubleTensor:\n",
    "    combined_state_totals = [state_total_prob[state] for state in state_total_prob]\n",
    "    return torch.stack(combined_state_totals, dim=0).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state_prob(state_total_prob: dict, total_prob: torch.DoubleTensor) -> dict:\n",
    "    new_state_prob: dict = {}\n",
    "    for state in state_total_prob:\n",
    "        new_state_prob[state] = state_total_prob[state] / total_prob\n",
    "    return new_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_state_prob(new_state_prob: dict, observations: list) -> dict:\n",
    "    observation_state_prob: dict = {}\n",
    "    for state in new_state_prob:\n",
    "        observation_state_prob[state] = {}\n",
    "        for tag in set(observations):\n",
    "            observation_state_prob[state][tag] = torch.DoubleTensor([])\n",
    "            for idx, observation in enumerate(observations):\n",
    "                probability = new_state_prob[state][idx] if observation == tag else 0\n",
    "                observation_state_prob[state][tag] = torch.cat((observation_state_prob[state][tag], torch.DoubleTensor([probability])))\n",
    "    return observation_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_state_prob(forward_prob: dict, backward_prob: dict, total_prob: torch.DoubleTensor, observations: list) -> dict:\n",
    "    transition_state_prob: dict = {}\n",
    "    for prev_state in emission:\n",
    "        transition_state_prob[prev_state] = {}\n",
    "        for state in emission:\n",
    "            transition_state_prob[prev_state][state] = torch.DoubleTensor([])\n",
    "            for i, observation in enumerate(observations[1:]):\n",
    "                idx = i + 1\n",
    "                probability = forward_prob[prev_state][idx-1]*backward_prob[state][idx]\n",
    "                probability *= transition[prev_state][state]*emission[state][observation]\n",
    "                probability /= total_prob[idx]\n",
    "                transition_state_prob[prev_state][state] = torch.cat((transition_state_prob[prev_state][state], torch.DoubleTensor([probability])))\n",
    "    return transition_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emissions(observation_state_prob: dict, new_state_prob: dict) -> dict:\n",
    "    emissions = {}\n",
    "    for state in new_state_prob:\n",
    "        emissions[state] = {}\n",
    "        for tag in observation_state_prob[state]:\n",
    "            emissions[state][tag] = torch.sum(observation_state_prob[state][tag])/torch.sum(new_state_prob[state])\n",
    "    return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions(transition_state_prob: dict, new_state_prob: dict) -> dict:\n",
    "    transitions = {}\n",
    "    for prev_state in transition_state_prob:\n",
    "        transitions[prev_state] = {}\n",
    "        for state in transition_state_prob:\n",
    "            transitions[prev_state][state] = torch.sum(transition_state_prob[prev_state][state])/torch.sum(new_state_prob[state])\n",
    "        transitions[prev_state]['STOP'] = new_state_prob[prev_state][-1]/torch.sum(new_state_prob[prev_state])\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init(new_state_prob: dict) -> dict:\n",
    "    init = {}\n",
    "    for state in new_state_prob:\n",
    "        init[state] = new_state_prob[state][0]\n",
    "    return init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iterate` runs the above computations and updates the initial, emission, and transition probabilities accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(observations: list):\n",
    "    forward: dict = get_forward_prob(observations)\n",
    "    backward: dict = get_backward_prob(observations)\n",
    "    state_total: dict = get_state_total_prob(forward, backward)\n",
    "    total: torch.DoubleTensor = get_total_prob(state_total, observations)\n",
    "    new_state: dict = get_new_state_prob(state_total, total)\n",
    "    observation_state: dict = get_observation_state_prob(new_state, observations)\n",
    "    transition_state: dict = get_transition_state_prob(forward, backward, total, observations)\n",
    "    emissions = get_emissions(observation_state, new_state)\n",
    "    transitions = get_transitions(transition_state, new_state)\n",
    "    init = get_init(new_state)\n",
    "    return init, transitions, emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I divide the data into sequences of 10 characters. I had to limit the length so much as longer sequences would result in smaller numbers, and more underflow/precision issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing unsupervised data...\n",
      "828448 sequences of unsupervised data of length 10\n"
     ]
    }
   ],
   "source": [
    "sequences: list = []\n",
    "sequence_labels: list = []\n",
    "current: list = []\n",
    "current_labels: list = []\n",
    "sequence_size: int = 10\n",
    "print(\"Dividing unsupervised data...\")\n",
    "for idx, character in enumerate(val_sequence):\n",
    "    current.append(character)\n",
    "    current_labels.append(val_labels[idx])\n",
    "    if idx % sequence_size == 0 and idx > 0:\n",
    "        sequences.append(current)\n",
    "        sequence_labels.append(current_labels)\n",
    "        current = []\n",
    "        current_labels = []\n",
    "print(\"{} sequences of unsupervised data of length {}\".format(len(sequences), sequence_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive function to check for nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_nans(d: dict) -> bool:\n",
    "    for i in d.values():\n",
    "        if isinstance(i,dict):\n",
    "            if has_nans(i):\n",
    "                return True\n",
    "        else:\n",
    "            if i != i:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I iterate over each sequence as a \"batch\" and update the global probabilities accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting...\")\n",
    "for sequence in sequences:\n",
    "    try:\n",
    "        batch_initials, batch_transitions, batch_emissions = iterate(sequence)\n",
    "        transition = batch_transitions if not has_nans(batch_transitions) else transition\n",
    "        if not has_nans(batch_emissions):\n",
    "            for state in emission:\n",
    "                emission[state].update(batch_emissions)\n",
    "    except:\n",
    "        pass\n",
    "print(\"Generated probabilities based on unlabeled data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Viterbi implementation for predicting optimal path based on provided probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state: str, probability: float, back_pointer):\n",
    "        self.back_pointer: Node = back_pointer\n",
    "        self.state: str = state\n",
    "        self.probability: float = probability\n",
    "\n",
    "\n",
    "def keys_match(dict_a: dict, dict_b: dict) -> bool:\n",
    "    return dict_a.keys() == dict_b.keys()\n",
    "\n",
    "\n",
    "def key_with_max_val(d: dict) -> str:\n",
    "    \"\"\"https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\"\"\"\n",
    "    v = list(d.values())\n",
    "    k = list(d.keys())\n",
    "    return k[v.index(max(v))]\n",
    "\n",
    "\n",
    "def node_with_max_prob(d: dict) -> Node:\n",
    "    max_node = Node(None, 0.0, None)\n",
    "    for node in d.values():\n",
    "        if node.probability > max_node.probability:\n",
    "            max_node = node\n",
    "    return max_node\n",
    "\n",
    "\n",
    "class Viterbi:\n",
    "    def __init__(self, initial_probabilities: dict, transition_probabilities: dict, emission_probabilities: dict,):\n",
    "        assert keys_match(initial_probabilities, emission_probabilities) and\\\n",
    "               keys_match(initial_probabilities, transition_probabilities), \"Hidden states must be consistent!\"\n",
    "        self.initial = initial_probabilities\n",
    "        self.emission = emission_probabilities\n",
    "        self.transitions = transition_probabilities\n",
    "\n",
    "    def predict_path(self, observations: list) -> list:\n",
    "        matrix: list = [{}]\n",
    "\n",
    "        for state in self.initial:\n",
    "            matrix[0][state] = Node(state, self.initial[state]*self.emission[state][observations[0]], None)\n",
    "\n",
    "        # fill initial probabilities\n",
    "        for prev_idx, observation in enumerate(observations[1:]):\n",
    "            matrix.append({})\n",
    "            for state in self.transitions:\n",
    "                transitions: dict = {}\n",
    "                for prev_state in matrix[prev_idx]:\n",
    "                    prev_prob = matrix[prev_idx][prev_state].probability\n",
    "                    transition_prob = self.transitions[prev_state][state]*prev_prob\n",
    "                    transitions[prev_state] = transition_prob\n",
    "                last_state = key_with_max_val(transitions)\n",
    "                probability = self.emission[state][observation]*transitions[last_state]\n",
    "                matrix[prev_idx+1][state] = Node(state, probability, matrix[prev_idx][last_state])\n",
    "\n",
    "        current_node: Node = node_with_max_prob(matrix[-1])\n",
    "        sequence: list = []\n",
    "        while current_node is not None:\n",
    "            sequence.insert(0, current_node.state)\n",
    "            current_node = current_node.back_pointer\n",
    "\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi = Viterbi(initial, transition, emission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds: list, labels: list) -> float:\n",
    "    corrects: list = []\n",
    "    for idx, pred in enumerate(preds):\n",
    "        corrects.append(pred == labels[idx])\n",
    "    return sum(corrects) / len(corrects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(preds, y):\n",
    "    true_positive_preds = 0\n",
    "    positive_preds = 0\n",
    "    for idx, pred in enumerate(preds):\n",
    "        if pred == '1':\n",
    "            positive_preds += 1\n",
    "            if y[idx] == '1':\n",
    "                true_positive_preds += 1\n",
    "    return true_positive_preds / positive_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(preds, y):\n",
    "    true_positive_preds = 0\n",
    "    positive_labels = 0\n",
    "    for idx, label in enumerate(y):\n",
    "        if label == '1':\n",
    "            positive_labels += 1\n",
    "            if preds[idx] == '1':\n",
    "                true_positive_preds += 1\n",
    "    return true_positive_preds / positive_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-414c5cef31ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_recal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-dcee97bc9ef2>\u001b[0m in \u001b[0;36mget_precision\u001b[0;34m(preds, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrue_positive_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpositive_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mpositive_preds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "idx = 0\n",
    "print(\"Evaluating...\")\n",
    "for sequence in sequences:\n",
    "    try:\n",
    "        predictions = viterbi.predict_path(sequence)\n",
    "        labels = sequence_labels[idx]\n",
    "        acc += get_accuracy(predictions, labels)\n",
    "        idx += 1\n",
    "    except:\n",
    "        pass\n",
    "    precision += get_precision(predictions, labels)\n",
    "    recall += get_recal(predictions, labels)\n",
    "precision = precision / (idx+1)\n",
    "recall = precision / (idx+1)\n",
    "print(\"Validation Metrics:\")\n",
    "print(\"\\tAccuracy: \", \"{:0.2f}%\".format(acc / (idx+1) * 100))\n",
    "print(\"\\tPrecision: \", \"{:0.2f}%\".format(precision))\n",
    "print(\"\\tRecall: \", \"{:0.2f}%\".format(recall))\n",
    "print(\"\\tF1 Score: \", \"{:0.2f}%\".format(f1score(precision, recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the % of positive labels to compare to my accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6517522340868426\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "for labels in sequence_labels:\n",
    "    for label in labels:\n",
    "        if label == '1':\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "print(pos/(pos+neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"test_data\" in globals():\n",
    "    test_sequence = [pair[0] for pair in test_data]\n",
    "    test_labels = [pair[1] for pair in test_data]\n",
    "    sequences: list = []\n",
    "    sequence_labels: list = []\n",
    "    current: list = []\n",
    "    current_labels: list = []\n",
    "    sequence_size: int = 10\n",
    "    print(\"Dividing test data...\")\n",
    "    for idx, character in enumerate(val_sequence):\n",
    "        current.append(character)\n",
    "        current_labels.append(val_labels[idx])\n",
    "        if idx % sequence_size == 0 and idx > 0:\n",
    "            sequences.append(current)\n",
    "            sequence_labels.append(current_labels)\n",
    "            current = []\n",
    "            current_labels = []\n",
    "    print(\"{} sequences of test data of length {}\".format(len(sequences), sequence_size))\n",
    "    \n",
    "    acc = 0\n",
    "    print(\"Evaluating Test Data...\")\n",
    "    for idx, sequence in enumerate(sequences):\n",
    "        predictions = viterbi.predict_path(sequence)\n",
    "        labels = sequence_labels[idx]\n",
    "        acc += accuracy(predictions, labels)\n",
    "        precision += get_precision(predictions, labels)\n",
    "        recall += get_recal(predictions, labels)\n",
    "    precision = precision / (idx+1)\n",
    "    recall = precision / (idx+1)\n",
    "    print(\"Test Metrics:\")\n",
    "    print(\"\\tAccuracy: \", \"{:0.2f}%\".format(acc / (idx+1) * 100))\n",
    "    print(\"\\tPrecision: \", \"{:0.2f}%\".format(precision))\n",
    "    print(\"\\tRecall: \", \"{:0.2f}%\".format(recall))\n",
    "    print(\"\\tF1 Score: \", \"{:0.2f}%\".format(f1score(precision, recall)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
