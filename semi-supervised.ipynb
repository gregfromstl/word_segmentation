{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Implementation\n",
    "### Mandarin Word Segmentation Using BaumWelch HMM\n",
    "For my semisupervised I attempted using the Baum Welch algorithm for tuning probabilities, using 1% of the provided training data (supervised portion) as initialization. I then ran the generated probabilities through the Viterbi algorithm to generate predicted sequences.\n",
    "Unfortunately my implmentation performs extremely poorly. I essentially achieved 50% accuracy, which is significantly worse than blindly guessing '1' every character (65% of the training data had the '1' tag).\n",
    "\n",
    "When evaluating on F1-Score, the results seem slightly better. The model's precision ranged from 0.6-0.67, but the recall (0.5) pulled the F1 down to around 0.57\n",
    "\n",
    "Understanding and implementing BaumWelch proved extremely difficult, but I think the failure to reach proper probabilities was due to precision flaws. When testing my code using the data from the spreadsheet, my results matched up for about 6-8 rows but then began to diverge more and more. I'm pretty sure this indicates differences in rounding/precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import log\n",
    "import numpy as np\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment variables. **Set `train_file` and `test_file` to the relative filepaths of the data.** If `test_file` is an empty string no test data will be used.\n",
    "I set the validation split to be 99% here so I'm only using 1% of the training labels, per the challenge requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file: str = 'data/train.tsv'\n",
    "test_file: str = 'data/test.tsv'\n",
    "val_split: float = 0.99\n",
    "\n",
    "states: dict = {\n",
    "    '0': 0,\n",
    "    '1': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file: str) -> list:\n",
    "    print(\"Loading data from file {}...\".format(file))\n",
    "    file = open(file, 'r')\n",
    "    data = []\n",
    "    for line in file:\n",
    "        pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        data.append(pieces)\n",
    "    print(\"Loaded {} sentences\".format(len(data)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file data/train.tsv...\n",
      "Loaded 8368167 sentences\n"
     ]
    }
   ],
   "source": [
    "train_data: list = load_data(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file data/test.tsv...\n",
      "Loaded 197696 sentences\n",
      "Splitting data...\n",
      "8284486  validation characters\n",
      "83681  training characters\n"
     ]
    }
   ],
   "source": [
    "if len(test_file) > 0:\n",
    "    test_data: list = load_data(test_file)\n",
    "print(\"Splitting data...\")\n",
    "num_train_samples: int = int(len(train_data)*(1-val_split))\n",
    "val_data: list = train_data[num_train_samples:]\n",
    "print(len(val_data), \" validation characters\")\n",
    "train_data: list = train_data[:num_train_samples]\n",
    "print(len(train_data), \" training characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æ™‚', '0']\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions taken from my Celtic Mutations code. They'll be used to compute the initialization probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities_from_counts(counts_dict: dict) -> dict:\n",
    "    counts_sum: int = sum(counts_dict.values())\n",
    "    probabilities_dict: dict = {}\n",
    "    for count_id in counts_dict:\n",
    "        count = counts_dict[count_id]\n",
    "        probabilities_dict[count_id] = count / counts_sum\n",
    "    assert round(sum(probabilities_dict.values()), 2) == 1.0, \"All probabilities should sum to 1 but got {}\".format(round(sum(probabilities_dict.values()), 2))\n",
    "    return probabilities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_with_max_val(d: dict) -> str:\n",
    "    \"\"\"https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\"\"\"\n",
    "    v = list(d.values())\n",
    "    k = list(d.keys())\n",
    "    return k[v.index(max(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions were adapted from my Celtic Mutations HMM to generate the initialization probabilities based on the first 1% of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_state_probabilities(data: list) -> dict:\n",
    "    initial_state_counts: dict = states.copy()\n",
    "    # equal probability of starting\n",
    "    for state in initial_state_counts:\n",
    "        initial_state_counts[state] += 1\n",
    "    initial_state_probabilities: dict = compute_probabilities_from_counts(initial_state_counts)\n",
    "    return initial_state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transition_state_probabilities(data: list) -> dict:\n",
    "    # create a dictionary with two levels, the first being the previous state and the second being the current state\n",
    "    transition_state_counts: dict = {state: states.copy() for state in states}\n",
    "    # since we enumerate over a list that excludes the first item, the enumeration index is one behind\n",
    "    for prev_idx, word in enumerate(data[1:]):\n",
    "        prev_state: str = data[prev_idx][1]\n",
    "        current_state: str = word[1]\n",
    "        if prev_state in transition_state_counts and current_state in transition_state_counts[prev_state]:\n",
    "            transition_state_counts[prev_state][current_state] += 1\n",
    "    # setting STOP count to 1 for all states to avoid zeros\n",
    "    for state in transition_state_counts:\n",
    "        transition_state_counts[state]['STOP'] = 1\n",
    "    transition_state_probabilities: dict = {state: {} for state in states}\n",
    "    for prev_state in transition_state_counts:\n",
    "        transition_state_probabilities[prev_state] = compute_probabilities_from_counts(transition_state_counts[prev_state])\n",
    "    return transition_state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emission_probabilities(data: list, all_observations: list) -> dict:\n",
    "    vocab = {obs: 1 for obs in set(all_observations)}\n",
    "    emission_counts_by_state: dict = {state: vocab for state in states}\n",
    "    for word_state_pair in data:\n",
    "        word, state = word_state_pair\n",
    "        if state in emission_counts_by_state:\n",
    "            # initialize word in state dict if the first occurrence of word X in state Y\n",
    "            if word not in emission_counts_by_state[state]:\n",
    "                emission_counts_by_state[state][word] = 0\n",
    "            emission_counts_by_state[state][word] += 1\n",
    "    emission_probabilities_by_state: dict = {state: {} for state in states}\n",
    "    for state in emission_counts_by_state:\n",
    "        emission_probabilities_by_state[state] = compute_probabilities_from_counts(emission_counts_by_state[state])\n",
    "    return emission_probabilities_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data: list, vocab: list) -> tuple:\n",
    "        print(\"Fitting model to provided dataset...\")\n",
    "        initial_state_probabilities = generate_initial_state_probabilities(data)\n",
    "        transition_probabilities = generate_transition_state_probabilities(data)\n",
    "        emission_probabilities = generate_emission_probabilities(data, vocab)\n",
    "        print(\"Model ready.\")\n",
    "        return initial_state_probabilities, transition_probabilities, emission_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I divide the validationb data between labels and characters, and fit the initial probabilities to the first 1% of training data.\n",
    "I pass the validation samples into the fit function for the sake of creating a dictionary of observations for emissions probabilities, but **the `val_sequence` variable does not include the labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model to provided dataset...\n",
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "val_sequence = [pair[0] for pair in val_data]\n",
    "val_labels = [pair[1] for pair in val_data]\n",
    "initial, transition, emission  = fit(train_data, val_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are each based on a section of the [Eisner HMM spreadsheet](https://docs.google.com/spreadsheets/d/1E4CKgcP9KmNsN6d-DWEYMuKBh-PFyXeswu48Axg6IQQ/edit#gid=1059181785). This is where I had the precision issues that prevented my implementation from reaching expected performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_prob(observations: list) -> dict:\n",
    "    forward_probabilities: dict = {}\n",
    "    for idx, observation in enumerate(observations):\n",
    "        for state in initial:\n",
    "            if idx == 0:\n",
    "                probability = initial[state]*emission[state][observation] if observation in emission[state] else 0\n",
    "                forward_probabilities[state] = torch.DoubleTensor([probability])\n",
    "            else:\n",
    "                probability = 0\n",
    "                for prev_state in transition:\n",
    "                    probability += forward_probabilities[prev_state][idx-1]*transition[prev_state][state]\n",
    "                probability *= emission[state][observation]\n",
    "                forward_probabilities[state] = torch.cat((forward_probabilities[state], torch.DoubleTensor([probability])))\n",
    "    return forward_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backward_prob(observations: list) -> dict:\n",
    "    backward_probabilities: dict = {}\n",
    "    for i in range(len(observations)):\n",
    "        idx = len(observations)-i-1\n",
    "        for state in initial:\n",
    "            if idx == len(observations)-1:\n",
    "                probability = transition[state]['STOP']\n",
    "                backward_probabilities[state] = torch.DoubleTensor([probability])\n",
    "            else:\n",
    "                probability = 0\n",
    "                for next_state in transition:\n",
    "                    probability += backward_probabilities[next_state][0]*transition[state][next_state]*emission[next_state][observations[idx+1]]\n",
    "                backward_probabilities[state] = torch.cat((torch.DoubleTensor([probability]), backward_probabilities[state]))\n",
    "    return backward_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_total_prob(forward_prob: dict, backward_prob: dict) -> dict:\n",
    "    state_total_prob: dict = {}\n",
    "    for state in forward_prob:\n",
    "        state_total_prob[state] = forward_prob[state] * backward_prob[state]\n",
    "    return state_total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_prob(state_total_prob: dict, observations: list) -> torch.DoubleTensor:\n",
    "    combined_state_totals = [state_total_prob[state] for state in state_total_prob]\n",
    "    return torch.stack(combined_state_totals, dim=0).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state_prob(state_total_prob: dict, total_prob: torch.DoubleTensor) -> dict:\n",
    "    new_state_prob: dict = {}\n",
    "    for state in state_total_prob:\n",
    "        new_state_prob[state] = state_total_prob[state] / total_prob\n",
    "    return new_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_state_prob(new_state_prob: dict, observations: list) -> dict:\n",
    "    observation_state_prob: dict = {}\n",
    "    for state in new_state_prob:\n",
    "        observation_state_prob[state] = {}\n",
    "        for tag in set(observations):\n",
    "            observation_state_prob[state][tag] = torch.DoubleTensor([])\n",
    "            for idx, observation in enumerate(observations):\n",
    "                probability = new_state_prob[state][idx] if observation == tag else 0\n",
    "                observation_state_prob[state][tag] = torch.cat((observation_state_prob[state][tag], torch.DoubleTensor([probability])))\n",
    "    return observation_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_state_prob(forward_prob: dict, backward_prob: dict, total_prob: torch.DoubleTensor, observations: list) -> dict:\n",
    "    transition_state_prob: dict = {}\n",
    "    for prev_state in emission:\n",
    "        transition_state_prob[prev_state] = {}\n",
    "        for state in emission:\n",
    "            transition_state_prob[prev_state][state] = torch.DoubleTensor([])\n",
    "            for i, observation in enumerate(observations[1:]):\n",
    "                idx = i + 1\n",
    "                probability = forward_prob[prev_state][idx-1]*backward_prob[state][idx]\n",
    "                probability *= transition[prev_state][state]*emission[state][observation]\n",
    "                probability /= total_prob[idx]\n",
    "                transition_state_prob[prev_state][state] = torch.cat((transition_state_prob[prev_state][state], torch.DoubleTensor([probability])))\n",
    "    return transition_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emissions(observation_state_prob: dict, new_state_prob: dict) -> dict:\n",
    "    emissions = {}\n",
    "    for state in new_state_prob:\n",
    "        emissions[state] = {}\n",
    "        for tag in observation_state_prob[state]:\n",
    "            emissions[state][tag] = torch.sum(observation_state_prob[state][tag])/torch.sum(new_state_prob[state])\n",
    "    return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions(transition_state_prob: dict, new_state_prob: dict) -> dict:\n",
    "    transitions = {}\n",
    "    for prev_state in transition_state_prob:\n",
    "        transitions[prev_state] = {}\n",
    "        for state in transition_state_prob:\n",
    "            transitions[prev_state][state] = torch.sum(transition_state_prob[prev_state][state])/torch.sum(new_state_prob[state])\n",
    "        transitions[prev_state]['STOP'] = new_state_prob[prev_state][-1]/torch.sum(new_state_prob[prev_state])\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init(new_state_prob: dict) -> dict:\n",
    "    init = {}\n",
    "    for state in new_state_prob:\n",
    "        init[state] = new_state_prob[state][0]\n",
    "    return init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iterate` runs the above computations and updates the initial, emission, and transition probabilities accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(observations: list):\n",
    "    forward: dict = get_forward_prob(observations)\n",
    "    backward: dict = get_backward_prob(observations)\n",
    "    state_total: dict = get_state_total_prob(forward, backward)\n",
    "    total: torch.DoubleTensor = get_total_prob(state_total, observations)\n",
    "    new_state: dict = get_new_state_prob(state_total, total)\n",
    "    observation_state: dict = get_observation_state_prob(new_state, observations)\n",
    "    transition_state: dict = get_transition_state_prob(forward, backward, total, observations)\n",
    "    emissions = get_emissions(observation_state, new_state)\n",
    "    transitions = get_transitions(transition_state, new_state)\n",
    "    init = get_init(new_state)\n",
    "    return init, transitions, emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I divide the data into sequences of 10 characters. I had to limit the length so much as longer sequences would result in smaller numbers, and more underflow/precision issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing unsupervised data...\n",
      "828448 sequences of unsupervised data of length 10\n"
     ]
    }
   ],
   "source": [
    "sequences: list = []\n",
    "sequence_labels: list = []\n",
    "current: list = []\n",
    "current_labels: list = []\n",
    "sequence_size: int = 10\n",
    "print(\"Dividing unsupervised data...\")\n",
    "for idx, character in enumerate(val_sequence):\n",
    "    current.append(character)\n",
    "    current_labels.append(val_labels[idx])\n",
    "    if idx % sequence_size == 0 and idx > 0:\n",
    "        sequences.append(current)\n",
    "        sequence_labels.append(current_labels)\n",
    "        current = []\n",
    "        current_labels = []\n",
    "print(\"{} sequences of unsupervised data of length {}\".format(len(sequences), sequence_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive function to check for nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_nans(d: dict) -> bool:\n",
    "    for i in d.values():\n",
    "        if isinstance(i,dict):\n",
    "            if has_nans(i):\n",
    "                return True\n",
    "        else:\n",
    "            if i != i:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I iterate over each sequence as a \"batch\" and update the global probabilities accordingly. I also limited it to the first 200,000 sequences for training as the full list took extremely long to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n",
      "Generated probabilities based on unlabeled data.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting...\")\n",
    "for sequence in sequences[:200000]:\n",
    "    try:\n",
    "        batch_initials, batch_transitions, batch_emissions = iterate(sequence)\n",
    "        transition = batch_transitions if not has_nans(batch_transitions) else transition\n",
    "        if not has_nans(batch_emissions):\n",
    "            for state in emission:\n",
    "                emission[state].update(batch_emissions)\n",
    "    except:\n",
    "        pass\n",
    "print(\"Generated probabilities based on unlabeled data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Viterbi implementation for predicting optimal path based on provided probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state: str, probability: float, back_pointer):\n",
    "        self.back_pointer: Node = back_pointer\n",
    "        self.state: str = state\n",
    "        self.probability: float = probability\n",
    "\n",
    "\n",
    "def keys_match(dict_a: dict, dict_b: dict) -> bool:\n",
    "    return dict_a.keys() == dict_b.keys()\n",
    "\n",
    "\n",
    "def key_with_max_val(d: dict) -> str:\n",
    "    \"\"\"https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\"\"\"\n",
    "    v = list(d.values())\n",
    "    k = list(d.keys())\n",
    "    return k[v.index(max(v))]\n",
    "\n",
    "\n",
    "def node_with_max_prob(d: dict) -> Node:\n",
    "    max_node = Node(None, 0.0, None)\n",
    "    for node in d.values():\n",
    "        if node.probability > max_node.probability:\n",
    "            max_node = node\n",
    "    return max_node\n",
    "\n",
    "\n",
    "class Viterbi:\n",
    "    def __init__(self, initial_probabilities: dict, transition_probabilities: dict, emission_probabilities: dict,):\n",
    "        assert keys_match(initial_probabilities, emission_probabilities) and\\\n",
    "               keys_match(initial_probabilities, transition_probabilities), \"Hidden states must be consistent!\"\n",
    "        self.initial = initial_probabilities\n",
    "        self.emission = emission_probabilities\n",
    "        self.transitions = transition_probabilities\n",
    "\n",
    "    def predict_path(self, observations: list) -> list:\n",
    "        matrix: list = [{}]\n",
    "\n",
    "        for state in self.initial:\n",
    "            matrix[0][state] = Node(state, self.initial[state]*self.emission[state][observations[0]], None)\n",
    "\n",
    "        # fill initial probabilities\n",
    "        for prev_idx, observation in enumerate(observations[1:]):\n",
    "            matrix.append({})\n",
    "            for state in self.transitions:\n",
    "                transitions: dict = {}\n",
    "                for prev_state in matrix[prev_idx]:\n",
    "                    prev_prob = matrix[prev_idx][prev_state].probability\n",
    "                    transition_prob = self.transitions[prev_state][state]*prev_prob\n",
    "                    transitions[prev_state] = transition_prob\n",
    "                last_state = key_with_max_val(transitions)\n",
    "                probability = self.emission[state][observation]*transitions[last_state]\n",
    "                matrix[prev_idx+1][state] = Node(state, probability, matrix[prev_idx][last_state])\n",
    "\n",
    "        current_node: Node = node_with_max_prob(matrix[-1])\n",
    "        sequence: list = []\n",
    "        while current_node is not None:\n",
    "            sequence.insert(0, current_node.state)\n",
    "            current_node = current_node.back_pointer\n",
    "\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi = Viterbi(initial, transition, emission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds: list, labels: list) -> float:\n",
    "    corrects: list = []\n",
    "    for idx, pred in enumerate(preds):\n",
    "        corrects.append(pred == labels[idx])\n",
    "    return sum(corrects) / len(corrects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(preds, y):\n",
    "    true_positive_preds = 0\n",
    "    positive_preds = 0\n",
    "    for idx, pred in enumerate(preds):\n",
    "        if pred == '1':\n",
    "            positive_preds += 1\n",
    "            if y[idx] == '1':\n",
    "                true_positive_preds += 1\n",
    "    return true_positive_preds / positive_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(preds, y):\n",
    "    true_positive_preds = 0\n",
    "    positive_labels = 0\n",
    "    for idx, label in enumerate(y):\n",
    "        if label == '1':\n",
    "            positive_labels += 1\n",
    "            if preds[idx] == '1':\n",
    "                true_positive_preds += 1\n",
    "    return true_positive_preds / positive_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Validation Metrics:\n",
      "\tAccuracy:  49.93%\n",
      "\tPrecision:  0.67\n",
      "\tRecall:  0.50\n",
      "\tF1 Score:  0.57\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "idx = 0\n",
    "print(\"Evaluating...\")\n",
    "for sequence in sequences:\n",
    "    try:\n",
    "        predictions = viterbi.predict_path(sequence)\n",
    "        labels = sequence_labels[idx]\n",
    "        a = get_accuracy(predictions, labels)\n",
    "        p = get_precision(predictions, labels)\n",
    "        r = get_recall(predictions, labels)\n",
    "        # make sure all functions succeed, then accumulate\n",
    "        acc += a\n",
    "        precision += p\n",
    "        recall += r\n",
    "        idx += 1\n",
    "    except:\n",
    "        pass\n",
    "precision = precision / (idx+1)\n",
    "recall = recall / (idx+1)\n",
    "print(\"Validation Metrics:\")\n",
    "print(\"\\tAccuracy: \", \"{:0.2f}%\".format(acc / (idx+1) * 100))\n",
    "print(\"\\tPrecision: \", \"{:0.2f}\".format(precision))\n",
    "print(\"\\tRecall: \", \"{:0.2f}\".format(recall))\n",
    "print(\"\\tF1 Score: \", \"{:0.2f}\".format(f1score(precision, recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing test data...\n",
      "19769 sequences of test data of length 10\n",
      "Evaluating...\n",
      "Testing Metrics:\n",
      "\tAccuracy:  49.70%\n",
      "\tPrecision:  0.61\n",
      "\tRecall:  0.50\n",
      "\tF1 Score:  0.55\n"
     ]
    }
   ],
   "source": [
    "if \"test_data\" in globals():\n",
    "    test_sequence = [pair[0] for pair in test_data]\n",
    "    test_labels = [pair[1] for pair in test_data]\n",
    "    sequences: list = []\n",
    "    sequence_labels: list = []\n",
    "    current: list = []\n",
    "    current_labels: list = []\n",
    "    sequence_size: int = 10\n",
    "    print(\"Dividing test data...\")\n",
    "    for idx, character in enumerate(test_sequence):\n",
    "        current.append(character)\n",
    "        current_labels.append(test_labels[idx])\n",
    "        if idx % sequence_size == 0 and idx > 0:\n",
    "            sequences.append(current)\n",
    "            sequence_labels.append(current_labels)\n",
    "            current = []\n",
    "            current_labels = []\n",
    "    print(\"{} sequences of test data of length {}\".format(len(sequences), sequence_size))\n",
    "    \n",
    "    acc = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    idx = 0\n",
    "    print(\"Evaluating...\")\n",
    "    for sequence in sequences:\n",
    "        try:\n",
    "            predictions = viterbi.predict_path(sequence)\n",
    "            labels = sequence_labels[idx]\n",
    "            a = get_accuracy(predictions, labels)\n",
    "            p = get_precision(predictions, labels)\n",
    "            r = get_recall(predictions, labels)\n",
    "            # make sure all functions succeed, then accumulate\n",
    "            acc += a\n",
    "            precision += p\n",
    "            recall += r\n",
    "            idx += 1\n",
    "        except:\n",
    "            pass\n",
    "    precision = precision / (idx+1)\n",
    "    recall = recall / (idx+1)\n",
    "    print(\"Testing Metrics:\")\n",
    "    print(\"\\tAccuracy: \", \"{:0.2f}%\".format(acc / (idx+1) * 100))\n",
    "    print(\"\\tPrecision: \", \"{:0.2f}\".format(precision))\n",
    "    print(\"\\tRecall: \", \"{:0.2f}\".format(recall))\n",
    "    print(\"\\tF1 Score: \", \"{:0.2f}\".format(f1score(precision, recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm definitely disappointed with this implementation, although not too surprised as I had a lot of trouble understanding how Baum-Welch operates. The spreadsheet was a helpful guide but the complexity of the algorithm clearly proved too much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
