{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file: str = 'data/train.tsv'\n",
    "test_file: str = ''\n",
    "val_split: float = 0.99\n",
    "\n",
    "states: dict = {\n",
    "    '0': 0,\n",
    "    '1': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file: str) -> list:\n",
    "    print(\"Loading data from file {}...\".format(file))\n",
    "    file = open(file, 'r')\n",
    "    data = []\n",
    "    for line in file:\n",
    "        pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        data.append(pieces)\n",
    "    print(\"Loaded {} sentences\".format(len(data)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file data/train.tsv...\n",
      "Loaded 8368167 sentences\n"
     ]
    }
   ],
   "source": [
    "train_data: list = load_data(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "8284486  validation characters\n",
      "83681  training characters\n"
     ]
    }
   ],
   "source": [
    "if len(test_file) > 0:\n",
    "    test_data: list = load_data(test_file)\n",
    "print(\"Splitting data...\")\n",
    "num_train_samples: int = int(len(train_data)*(1-val_split))\n",
    "val_data: list = train_data[num_train_samples:]\n",
    "print(len(val_data), \" validation characters\")\n",
    "train_data: list = train_data[:num_train_samples]\n",
    "print(len(train_data), \" training characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æ™‚', '0']\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities_from_counts(counts_dict: dict) -> dict:\n",
    "    counts_sum: int = sum(counts_dict.values())\n",
    "    probabilities_dict: dict = {}\n",
    "    for count_id in counts_dict:\n",
    "        count = counts_dict[count_id]\n",
    "        probabilities_dict[count_id] = count / counts_sum\n",
    "    assert round(sum(probabilities_dict.values()), 2) == 1.0, \"All probabilities should sum to 1 but got {}\".format(round(sum(probabilities_dict.values()), 2))\n",
    "    return probabilities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_with_max_val(d: dict) -> str:\n",
    "    \"\"\"https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\"\"\"\n",
    "    v = list(d.values())\n",
    "    k = list(d.keys())\n",
    "    return k[v.index(max(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_state_probabilities(data: list) -> dict:\n",
    "    initial_state_counts: dict = states.copy()\n",
    "    initial_state: str = data[0][1]\n",
    "    if initial_state in initial_state_counts:\n",
    "        initial_state_counts[initial_state] += 1\n",
    "    initial_state_probabilities: dict = compute_probabilities_from_counts(initial_state_counts)\n",
    "    return initial_state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transition_state_probabilities(data: list) -> dict:\n",
    "    # create a dictionary with two levels, the first being the previous state and the second being the current state\n",
    "    transition_state_counts: dict = {state: states.copy() for state in states}\n",
    "    # since we enumerate over a list that excludes the first item, the enumeration index is one behind\n",
    "    for prev_idx, word in enumerate(data[1:]):\n",
    "        prev_state: str = data[prev_idx][1]\n",
    "        current_state: str = word[1]\n",
    "        if prev_state in transition_state_counts and current_state in transition_state_counts[prev_state]:\n",
    "            transition_state_counts[prev_state][current_state] += 1\n",
    "    for state in transition_state_counts:\n",
    "        transition_state_counts[state]['STOP'] = 0\n",
    "    transition_state_counts[current_state]['STOP'] += 1\n",
    "    transition_state_probabilities: dict = {state: {} for state in states}\n",
    "    for prev_state in transition_state_counts:\n",
    "        transition_state_probabilities[prev_state] = compute_probabilities_from_counts(transition_state_counts[prev_state])\n",
    "    return transition_state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emission_probabilities(data: list, sequence: list) -> dict:\n",
    "    all_observations: dict = {obs: 0 for obs in set(sequence)}\n",
    "    emission_counts_by_state: dict = {state: all_observations for state in states}\n",
    "    for word_state_pair in data:\n",
    "        word, state = word_state_pair\n",
    "        if state in emission_counts_by_state:\n",
    "            # initialize word in state dict if the first occurrence of word X in state Y\n",
    "            if word not in emission_counts_by_state[state]:\n",
    "                emission_counts_by_state[state][word] = 0\n",
    "            emission_counts_by_state[state][word] += 1\n",
    "    emission_probabilities_by_state: dict = {state: {} for state in states}\n",
    "    for state in emission_counts_by_state:\n",
    "        emission_probabilities_by_state[state] = compute_probabilities_from_counts(emission_counts_by_state[state])\n",
    "    return emission_probabilities_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data: list, sequence: list) -> tuple:\n",
    "        print(\"Fitting model to provided dataset...\")\n",
    "        initial_state_probabilities = generate_initial_state_probabilities(data)\n",
    "        transition_probabilities = generate_transition_state_probabilities(data)\n",
    "        emission_probabilities = generate_emission_probabilities(data, sequence)\n",
    "        print(\"Model ready.\")\n",
    "        return initial_state_probabilities, transition_probabilities, emission_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_prob(observations: list) -> dict:\n",
    "    forward_probabilities: dict = {}\n",
    "    for idx, observation in enumerate(observations):\n",
    "        for state in initial:\n",
    "            if idx == 0:\n",
    "                probability = initial[state]*emission[state][observation] if observation in emission[state] else 0\n",
    "                forward_probabilities[state] = torch.DoubleTensor([probability])\n",
    "            else:\n",
    "                probability = 0\n",
    "                for prev_state in transitions:\n",
    "                    probability += forward_probabilities[prev_state][idx-1]*transitions[prev_state][state]\n",
    "                probability *= emission[state][observation]\n",
    "                forward_probabilities[state] = torch.cat((forward_probabilities[state], torch.DoubleTensor([probability])))\n",
    "    return forward_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backward_prob(observations: list) -> dict:\n",
    "    backward_probabilities: dict = {}\n",
    "    for i in range(len(observations)):\n",
    "        idx = len(observations)-i-1\n",
    "        for state in initial:\n",
    "            if idx == len(observations)-1:\n",
    "                probability = transitions[state]['STOP']\n",
    "                backward_probabilities[state] = torch.DoubleTensor([probability])\n",
    "            else:\n",
    "                probability = 0\n",
    "                for next_state in transitions:\n",
    "                    probability += backward_probabilities[state][0]*transitions[state][next_state]*emission[next_state][observations[idx+1]]\n",
    "                backward_probabilities[state] = torch.cat((torch.DoubleTensor([probability]), backward_probabilities[state]))\n",
    "    return backward_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_total_prob(forward_prob: dict, backward_prob: dict) -> dict:\n",
    "    state_total_prob: dict = {}\n",
    "    for state in forward_prob:\n",
    "        state_total_prob[state] = forward_prob[state] * backward_prob[state]\n",
    "    return state_total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_prob(state_total_prob: dict, observations: list) -> torch.DoubleTensor:\n",
    "    combined_state_totals = [state_total_prob[state] for state in state_total_prob]\n",
    "    return torch.stack(combined_state_totals, dim=0).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state_prob(state_total_prob: dict, total_prob: torch.DoubleTensor) -> dict:\n",
    "    new_state_prob: dict = {}\n",
    "    for state in state_total_prob:\n",
    "        new_state_prob[state] = state_total_prob[state] / total_prob\n",
    "    return new_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_state_prob(new_state_prob: dict, observations: list) -> dict:\n",
    "    observation_state_prob: dict = {}\n",
    "    for state in new_state_prob:\n",
    "        observation_state_prob[state] = {}\n",
    "        for tag in set(observations):\n",
    "            observation_state_prob[state][tag] = torch.DoubleTensor([])\n",
    "            for idx, observation in enumerate(observations):\n",
    "                probability = new_state_prob[state][idx] if observation == tag else 0\n",
    "                observation_state_prob[state][tag] = torch.cat((observation_state_prob[state][tag], torch.DoubleTensor([probability])))\n",
    "    return observation_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_state_prob(forward_prob: dict, backward_prob: dict, total_prob: torch.DoubleTensor, observations: list) -> dict:\n",
    "    transition_state_prob: dict = {}\n",
    "    for prev_state in emission:\n",
    "        transition_state_prob[prev_state] = {}\n",
    "        for state in emission:\n",
    "            transition_state_prob[prev_state][state] = torch.DoubleTensor([])\n",
    "            for i, observation in enumerate(observations[1:]):\n",
    "                idx = i + 1\n",
    "                probability = forward_prob[prev_state][idx-1]*backward_prob[state][idx]\n",
    "                probability *= transitions[prev_state][state]*emission[state][observation]\n",
    "                probability /= total_prob[idx]\n",
    "                transition_state_prob[prev_state][state] = torch.cat((transition_state_prob[prev_state][state], torch.DoubleTensor([probability])))\n",
    "    return transition_state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emissions(observation_state_prob: dict, new_state_prob: dict) -> dict:\n",
    "    emissions = {}\n",
    "    for state in new_state_prob:\n",
    "        emissions[state] = {}\n",
    "        for tag in observation_state_prob[state]:\n",
    "            emissions[state][tag] = torch.sum(observation_state_prob[state][tag])/torch.sum(new_state_prob[state])\n",
    "    return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions(transition_state_prob: dict, new_state_prob: dict) -> dict:\n",
    "    transitions = {}\n",
    "    for prev_state in transition_state_prob:\n",
    "        transitions[prev_state] = {}\n",
    "        for state in transition_state_prob:\n",
    "            transitions[prev_state][state] = torch.sum(transition_state_prob[prev_state][state])/torch.sum(new_state_prob[state])\n",
    "        transitions[prev_state]['STOP'] = new_state_prob[prev_state][-1]/torch.sum(new_state_prob[prev_state])\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init(new_state_prob: dict) -> dict:\n",
    "    init = {}\n",
    "    for state in new_state_prob:\n",
    "        init[state] = new_state_prob[state][0]\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(observations: list):\n",
    "    forward: dict = get_forward_prob(observations)\n",
    "    print('A')\n",
    "    backward: dict = get_backward_prob(observations)\n",
    "    print('B')\n",
    "    state_total: dict = get_state_total_prob(forward_prob, backward_prob)\n",
    "    print('C')\n",
    "    total: torch.DoubleTensor = get_total_prob(state_total_prob, observations)\n",
    "    print('D')\n",
    "    new_state: dict = get_new_state_prob(state_total_prob, total_prob)\n",
    "    print('E')\n",
    "    observation_state: dict = observation_state_prob(new_state_prob, observations)\n",
    "    print('F')\n",
    "    transition_state: dict = transition_state_prob(forward_prob, backward_prob, total_prob, observations)\n",
    "    emissions = get_emissions(observation_state_prob, new_state_prob)\n",
    "    transitions = get_transitions(transition_state_prob, new_state_prob)\n",
    "    init = get_init(new_state_prob)\n",
    "    return init, transitions, emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model to provided dataset...\n",
      "Model ready.\n",
      "A\n",
      "B\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-0a3fb0c2b68f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-79fcb7deeb6a>\u001b[0m in \u001b[0;36miterate\u001b[0;34m(observations)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbackward\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstate_total\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_total_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_total_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-752d40470447>\u001b[0m in \u001b[0;36mstate_total_prob\u001b[0;34m(forward_prob, backward_prob)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstate_total_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstate_total_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mforward_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mstate_total_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbackward_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_total_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "val_sequence = [pair[0] for pair in val_data]\n",
    "initial, transitions, emission  = fit(train_data, val_sequence)\n",
    "iterate(val_sequence[:1000])\n",
    "print(e.transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-4d311e85a297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSemiSupervisedHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m i = e.iterate(['2', '3', '3', '2', '3', '2', '3', '2', '2', '3', '1', '3', '3', '1', '1', '1', \n\u001b[0;32m----> 8\u001b[0;31m                  '2', '1', '1', '1', '3', '1', '2', '1', '1', '1', '2', '3', '3', '2', '3', '2', '2'])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# for c, y in enumerate(i['H']['C']):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-0bb084251011>\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mforward_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "init = {'H': 0.5, 'C': 0.5}\n",
    "emit = {'H': {'1': 0.1, '2': 0.2, '3': 0.7},\n",
    "        'C': {'1': 0.7, '2': 0.2, '3': 0.1}}\n",
    "transit = {'H': {'H': 0.8, 'C': 0.1, 'STOP': 0.1},\n",
    "           'C': {'H': 0.1, 'C': 0.8, 'STOP': 0.1}}\n",
    "e = SemiSupervisedHMM(init, emit, transit)\n",
    "i = e.iterate(['2', '3', '3', '2', '3', '2', '3', '2', '2', '3', '1', '3', '3', '1', '1', '1', \n",
    "                 '2', '1', '1', '1', '3', '1', '2', '1', '1', '1', '2', '3', '3', '2', '3', '2', '2'])\n",
    "\n",
    "# for c, y in enumerate(i['H']['C']):\n",
    "#     print(c+1, y.item())\n",
    "# for c, y in enumerate(i['C']['H']):\n",
    "#     print(c+1, y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state: str, probability: float, back_pointer):\n",
    "        self.back_pointer: Node = back_pointer\n",
    "        self.state: str = state\n",
    "        self.probability: float = probability\n",
    "\n",
    "\n",
    "def keys_match(dict_a: dict, dict_b: dict) -> bool:\n",
    "    return dict_a.keys() == dict_b.keys()\n",
    "\n",
    "\n",
    "def key_with_max_val(d: dict) -> str:\n",
    "    \"\"\"https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\"\"\"\n",
    "    v = list(d.values())\n",
    "    k = list(d.keys())\n",
    "    return k[v.index(max(v))]\n",
    "\n",
    "\n",
    "def node_with_max_prob(d: dict) -> Node:\n",
    "    max_node = Node(None, 0.0, None)\n",
    "    for node in d.values():\n",
    "        if node.probability > max_node.probability:\n",
    "            max_node = node\n",
    "    return max_node\n",
    "\n",
    "\n",
    "class Viterbi:\n",
    "    def __init__(self, initial_probabilities: dict, emission_probabilities: dict, transition_probabilities: dict):\n",
    "        assert keys_match(initial_probabilities, emission_probabilities) and\\\n",
    "               keys_match(initial_probabilities, transition_probabilities), \"Hidden states must be consistent!\"\n",
    "        self.initial = initial_probabilities\n",
    "        self.emission = emission_probabilities\n",
    "        self.transitions = transition_probabilities\n",
    "\n",
    "    def predict_path(self, observations: list) -> list:\n",
    "        matrix: list = [{}]\n",
    "\n",
    "        for state in self.initial:\n",
    "            matrix[0][state] = Node(state, self.initial[state]*self.emission[state][observations[0]], None)\n",
    "\n",
    "        # fill initial probabilities\n",
    "        for prev_idx, observation in enumerate(observations[1:]):\n",
    "            matrix.append({})\n",
    "            for state in self.transitions:\n",
    "                transitions: dict = {}\n",
    "                for prev_state in matrix[prev_idx]:\n",
    "                    prev_prob = matrix[prev_idx][prev_state].probability\n",
    "                    transition_prob = self.transitions[prev_state][state]*prev_prob\n",
    "                    transitions[prev_state] = transition_prob\n",
    "                last_state = key_with_max_val(transitions)\n",
    "                probability = self.emission[state][observation]*transitions[last_state]\n",
    "                matrix[prev_idx+1][state] = Node(state, probability, matrix[prev_idx][last_state])\n",
    "\n",
    "        current_node: Node = node_with_max_prob(matrix[-1])\n",
    "        sequence: list = []\n",
    "        while current_node is not None:\n",
    "            sequence.insert(0, current_node.state)\n",
    "            current_node = current_node.back_pointer\n",
    "\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
